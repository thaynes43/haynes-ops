apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: omni
  namespace: frontend
spec:
  interval: 30m
  chartRef:
    kind: OCIRepository
    name: app-template
  maxHistory: 2
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false

  values:
    controllers:
      omni:
        type: deployment
        strategy: Recreate          # avoid port/interface conflicts during upgrades
        replicas: 1

        annotations:
          reloader.stakater.com/auto: "true"

        pod:
          hostNetwork: true         # mirror compose: network_mode: host
          dnsPolicy: ClusterFirstWithHostNet
          securityContext:
            runAsUser: 0
            runAsGroup: 0
            fsGroup: 0
          terminationGracePeriodSeconds: 5

        # optional safety; with Recreate you shouldn't need it, but it helps clean leftovers
        initContainers:
          cleanup-wireguard:
            image:
              repository: alpine
              tag: "3.20"
            command:
              - /bin/sh
              - -c
              - |
                set -eux
                apk add --no-cache iproute2 psmisc
                # remove stale interface if it exists
                ip link show siderolink >/dev/null 2>&1 && ip link delete siderolink || true
                # free any stale listeners on machine API port
                fuser -k 8090/tcp 2>/dev/null || true
                fuser -k 8090/udp 2>/dev/null || true
            securityContext:
              privileged: true
              capabilities:
                add: ["NET_ADMIN"]

        containers:
          app:
            image:
              repository: ghcr.io/siderolabs/omni
              tag: v1.1.3
              pullPolicy: IfNotPresent

            envFrom:
              - secretRef:
                  name: omni-secret     # holds OMNI_* / ADVERTISED_* / SAML vars you already have

            # mirror compose flags; serve TLS directly (and still fine behind your Ingress)
            args:
              - --account-id=$(OMNI_ACCOUNT_UUID)
              - --name=$(OMNI_NAME)
              - --cert=/tls.crt
              - --key=/tls.key
              - --machine-api-cert=/tls.crt
              - --machine-api-key=/tls.key
              - --private-key-source=file:///omni.asc
              - --event-sink-port=$(EVENT_SINK_PORT)
              - --bind-addr=0.0.0.0:8080
              - --machine-api-bind-addr=0.0.0.0:8090
              - --k8s-proxy-bind-addr=0.0.0.0:8100
              - --advertised-api-url=$(ADVERTISED_API_URL)
              - --advertised-kubernetes-proxy-url=$(ADVERTISED_K8S_PROXY_URL)
              - --machine-api-advertised-url=$(SIDEROLINK_API_ADVERTISED_URL)
              # optional (only if you set it in the secret), same as compose:
              - --siderolink-wireguard-advertised-addr=$(SIDEROLINK_WIREGUARD_ADVERTISED_ADDR)
              # SAML
              - --auth-saml-enabled=$(AUTH_SAML_ENABLED)
              - --auth-saml-url=$(AUTH_SAML_METADATA_URL)
              # embedded etcd like you had before
              - --etcd-embedded=true
              - --etcd-embedded-unsafe-fsync=true

            # make cgroup/device access a non-issue
            securityContext:
              privileged: true
              allowPrivilegeEscalation: true
              readOnlyRootFilesystem: false
              capabilities:
                add: ["NET_ADMIN","NET_RAW"]

            resources:
              requests:
                cpu: 10m
                memory: 500Mi
              limits:
                memory: 16Gi

            # containerPort is informational with hostNetwork, but keep names for Service/Ingress
            ports:
              - { name: http,    containerPort: 8080 }
              - { name: machine, containerPort: 8090 }
              - { name: kube,    containerPort: 8100 }

            probes:
              liveness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /api/health
                    port: 8080
                  initialDelaySeconds: 60
                  periodSeconds: 30
                  timeoutSeconds: 10
                  failureThreshold: 3
              readiness:
                enabled: true
                custom: true
                spec:
                  httpGet:
                    path: /api/health
                    port: 8080
                  initialDelaySeconds: 30
                  periodSeconds: 10
                  timeoutSeconds: 5
                  failureThreshold: 3

    service:
      omni:
        controller: omni
        type: ClusterIP
        ports:
          http:    { port: 8080, targetPort: http }
          machine: { port: 8090, targetPort: machine }
          kube:    { port: 8100, targetPort: kube }

    persistence:
      # etcd data, like ${ETCD_VOLUME_PATH}:/_out/etcd
      etcd:
        existingClaim: omni
        globalMounts:
          - path: /_out/etcd

      # map /dev/net/tun just like compose "devices: - /dev/net/tun"
      dev-net-tun:
        type: hostPath
        hostPath: /dev/net/tun
        hostPathType: CharDevice
        globalMounts:
          - path: /dev/net/tun

      # private key (same idea as ${ETCD_ENCRYPTION_KEY}:/omni.asc)
      deploy-key:
        type: secret
        name: omni-secret
        defaultMode: 256
        globalMounts:
          - path: /omni.asc
            subPath: OMNI_ASC

      # TLS cert/key (compose mounts /tls.crt and /tls.key)
      tls:
        type: secret
        name: omni-tls             # create a kubernetes.io/tls secret with tls.crt/tls.key
        defaultMode: 256
        globalMounts:
          - path: /tls.crt
            subPath: tls.crt
          - path: /tls.key
            subPath: tls.key
